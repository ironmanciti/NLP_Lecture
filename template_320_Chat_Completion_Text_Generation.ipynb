{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5a91499-2154-45fc-b4b0-10c888d61c6d",
   "metadata": {},
   "source": [
    "# Text Generation models\n",
    "\n",
    "- GPT-4o\n",
    "- GPT-4o-mini\n",
    "- GPT-4o with image inpus\n",
    "- GPT-4o-search-preview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94635dde-ab9f-4d32-b3aa-5db234bb122d",
   "metadata": {},
   "source": [
    "## Chat Completion API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a44bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U openai\n",
    "# !pip install -U tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621302d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09ecb901-f941-40c2-9dcb-e68d6738823a",
   "metadata": {},
   "source": [
    "- 메시지는 메시지 개체의 배열이어야 하며, 각 개체에는role(“system\", “user\" 또는 “assistant\")과 content가 있습니다. 대화는 하나의 메시지만큼 짧을 수도 있고 여러 번 주고받을 수도 있습니다.\n",
    "- 대화는 먼저 system 메시지로 형식화되고 이어서 user 메시지와 assistanc 메시지가 교대로 표시됩니다.  \n",
    "- system 메시지는 assistant의 동작을 설정하는 데 도움이 됩니다. 예를 들어, assitant의 성격을 수정하거나 대화 전반에 걸쳐 assistant가 어떻게 행동해야 하는지에 대한 구체적인 지침을 제공할 수 있습니다. 그러나 system 메시지는 선택 사항이며 system 메시지가 없는 모델의 동작은 \"당신은 도움이 되는 조수입니다\"와 같은 일반적인 메시지를 사용하는 것과 유사할 가능성이 높습니다.  \n",
    "- \n",
    "User 메시지는 assistant가 응답할 요청이나 설명을 제공합니다. Assistant 메시지는 이전 assistant 응답을 저장하지만 원하는 동작의 예를 제공하기 위해 user가 작성할 수도 있습니다  .- \n",
    "사용자 지침이 이전 메시지를 참조할 때 대화 기록을 포함하는 것이 중요합니다. 위의 예에서 사용자의 마지막 질문인 \" Where was it played?\" 는 2020년 월드 시리즈에 대한 이전 메시지의 context 에서만 의미가 있습니다. 모델에는 과거 요청에 대한 기억이 없기 때문에 모든 관련 정보는 각 요청의 대화 기록의 일부로 제공되어야 합니다. 대화가 모델의 토큰 제한에 맞지 않으면 어떤 방식으로든 줄여야 합니다 .\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854332c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a9cf46b-2ef0-4a0f-8b7b-42283e97821d",
   "metadata": {},
   "source": [
    "### temperature가 출력에 미치는 영향\n",
    "- 낮은 온도(예: 0.1): 값이 낮을수록 모델의 출력은 더욱 결정적이고 집중적입니다. 모델이 가장 높은 확률의 다음 단어를 선택할 가능성이 더 높기 때문에 응답이 더 예측 가능합니다. 이 설정은 사실적 답변이나 데이터 추출과 같이 정확하고 일관된 출력이 필요한 애플리케이션에 유용합니다.\n",
    "\n",
    "- 고온(예: 0.9): 값이 높을수록 모델의 출력은 더 무작위적이고 창의적이 됩니다. 모델이 덜 가능성 있는 단어를 선택할 가능성이 높기 때문에 응답이 더 다양합니다. 이 설정은 스토리 생성, 브레인스토밍 또는 대화와 같이 변화가 필요한 창의적인 작업에 유용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa736578",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54279f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76df57f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9cef9eb-d558-4949-bdbd-3f2a8d28f804",
   "metadata": {},
   "source": [
    "### RAG(Retrieval Augmented Generation)을 이용한 질문 답변"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec434c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wikipedia 페이지의 URL\n",
    "#url = \"https://en.wikipedia.org/wiki/Curling_at_the_2022_Winter_Olympics\"\n",
    "# 페이지 내용 가져오기\n",
    "# 페이지 내용 중에서 필요한 부분 추출 (예시로 본문 전체를 가져옵니다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9837fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "444715f4-8b62-4c16-a9d3-aa037d3fb67e",
   "metadata": {},
   "source": [
    "### 모든 응답에는 'finish_reason'이 포함되며, 'finish_reason'의 가능한 값은 다음과 같습니다:\n",
    "- stop: API가 완전한 메시지를 반환하거나, stop 매개변수를 통해 제공된 중단 시퀀스 중 하나에 의해 메시지가 종료됨\n",
    "- length: max_tokens 매개변수 또는 토큰 제한으로 인해 완전하지 않은 모델 출력\n",
    "- function_call: 모델이 함수를 호출하기로 결정함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e097ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d884b7e7-03d3-4668-8f5b-0e7b447dbeb5",
   "metadata": {},
   "source": [
    "## Token 관리\n",
    "- \"ChatGPT is great!“ 는 6개의 토큰으로 인코딩됩니다 $\\rightarrow$ [\"Chat\", \"G\", \"PT\", \" is\", \" great\", \"!\"]\n",
    "- 예를 들어, API 호출이 메시지 입력에서 10개의 토큰을 사용하고 메시지 출력에서 ​​20개의 토큰을 받은 경우 30개의 토큰에 대한 요금이 청구됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af84874",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b3a804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9c6c38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cab3f31a-ec6c-4c96-9d64-2411e6111eaa",
   "metadata": {},
   "source": [
    "## 재현 가능한 출력 \n",
    "- SEED 매개 변수 사용\n",
    "\n",
    "- temperature 설정\n",
    "  \n",
    "    - 온도 = 0.0: 모델은 매번 동일한 입력에 대해 동일한 출력을 생성하므로 완전히 결정적입니다. 이는 가장 예측 가능하고 안정적인 응답이 필요할 때 유용합니다.   \n",
    "    - 0.0과 1.0 사이의 온도: 이것은 가장 일반적으로 사용되는 범위로, 창의성과 결정론 사이의 균형을 허용합니다.   \n",
    "    - 온도 > 1.0: 가능하지만 출력이 너무 무작위적이어서 대부분의 애플리케이션에 덜 유용할 수 있습니다. 일반적으로 권장되지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc1432a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4a4bff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4caff43a-c60b-49a2-a0df-d65b59eb6a91",
   "metadata": {},
   "source": [
    "### 모델에 인터넷의 최신 정보에 대한 액세스 권한을 부여\n",
    "- `gpt-4o-search-preview` 또는 `gpt-4o-mini-search-preview` 모델 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831c4c10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df59a31f-7fdc-4ffe-839c-87a3c6b3175f",
   "metadata": {},
   "source": [
    "## 실습 : 위의 messages 내용을 각자 수정해 가면서 API 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c3a814",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
