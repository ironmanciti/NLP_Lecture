{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "412ac8b9",
   "metadata": {
    "id": "Q15ChKHSG8y4"
   },
   "source": [
    "# 080. seq2seq 기계번역 모델 작성\n",
    "\n",
    "### Encoder-Decoder model\n",
    "\n",
    "\n",
    "- 영어-한국어 번역"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e92ca14",
   "metadata": {
    "id": "_kawPBRbh6NO"
   },
   "source": [
    "### 한글 Glove file download\n",
    "\n",
    "한글 GloVe 파일이란, GloVe(Global Vectors for Word Representation) 방식으로 훈련된 한국어 단어 임베딩 벡터 파일을 말합니다. GloVe는 단어 간의 통계적 동시 출현 정보를 기반으로 정적인 벡터 표현을 학습하는 방법으로, Word2Vec과 유사하지만 약간 다른 방식으로 훈련됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a587a5ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5deeca92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6a5887",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf4d8dcd",
   "metadata": {
    "id": "88dOCLrOG8zA"
   },
   "source": [
    "## 입력 data list 작성  \n",
    "\n",
    "### 1. input_texts     : original language 의 input text  \n",
    "\n",
    "\n",
    "### 2. Teacher Forcing 용 input / target data 생성\n",
    "\n",
    "- target_texts_inputs  : 1 만큼 offset 된 target language sentence $\\rightarrow$ <sos>(시작 토큰)부터 문장의 끝 직전까지   \n",
    "- target_texts  : target language sentence  $\\rightarrow$ 문장의 시작부터 <eos> (종료 토큰)까지\n",
    "\n",
    "| 항목                    | 내용                             |\n",
    "| --------------------- | ------------------------------ |\n",
    "| `target_texts_inputs` | `['<sos>', '나는', '밥을']`        |\n",
    "| `target_texts`        | `['나는', '밥을', '먹었다', '<eos>']` |\n",
    "\n",
    "\n",
    "\n",
    "- data 는 http://www.manythings.org/anki/  (Tab-delimited Bilingual Sentence Pairs) 에서 download  \n",
    "\n",
    "\n",
    "    - English(input) + `\\t` + The Other Language(target) + `\\t` + Attribution(기여자) 형식으로 구성\n",
    "        ex)\n",
    "        - Hi.\t안녕.\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #8355888 (Eunhee).\n",
    "        - I like horses.\t나는 말을 좋아해.\tCC-BY 2.0 (France) Attribution: tatoeba.org #1331062 (Kirschen112) & #8365125 (Eunhee)\n",
    "        - We had fun with Tom.\t우리는 톰과 즐거운 시간을 가졌다.\tCC-BY 2.0 (France) Attribution: tatoeba.org #6845055 (CK) & #6845295 (dalgarak)\n",
    "\n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1383246d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cfefc410",
   "metadata": {
    "id": "HlozoHc8GI8C"
   },
   "source": [
    "- teacher forcing 용 input, target 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76eb4a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the data\n",
    "# load data\n",
    "    # input 과 target translation 구분\n",
    "    # target input 과 output 을 teacher forcing 입력 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563dca74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47fae845",
   "metadata": {
    "id": "9xJ-KzkAG8zK"
   },
   "source": [
    "## Tokenization\n",
    "\n",
    "- language 가 2 개 이므로 언어별로 서로 다른 tokenizer 생성. 따라서, 2 개의 word_index 구성\n",
    "\n",
    "### 영어 input text 의 tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32821f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 영어 텍스트 데이터를 위한 Tokenizer 객체 생성 (최대 단어 수 지정)\n",
    "# 영어 텍스트 데이터를 사용하여 토크나이저 학습 수행 (단어 인덱스 구축)\n",
    "# 영어 텍스트 데이터를 시퀀스로 변환\n",
    "# 1500번째 시퀀스 출력\n",
    "# 1500번째 원본 영어 텍스트 출력\n",
    "# 1500번째 시퀀스의 각 인덱스를 단어로 변환하여 리스트로 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c61a55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 영어 단어를 인덱스로 매핑한 사전 가져오기\n",
    "# 고유한 입력 토큰 수 출력\n",
    "# 사용할 단어 수 계산 (최대 어휘 크기와 실제 단어 수 + 1 중 작은 값)\n",
    "# 입력 텍스트의 최대 길이 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12059efa",
   "metadata": {
    "id": "UnAyAZK6G8zU"
   },
   "source": [
    "### 한국어 Input Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d86108",
   "metadata": {
    "id": "RvBj6QEPG8zX"
   },
   "source": [
    "### Translation language 의 tokenizer\n",
    "- 주의 사항 : $<sos>, <eos>$때문에 special character 를 filtering 하면 안됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9339894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한국어 텍스트 데이터를 위한 Tokenizer 객체 생성 (최대 단어 수 지정, 필터 비활성화)\n",
    "# 한국어 입력 및 타겟 텍스트 데이터를 사용하여 토크나이저 학습 수행 (단어 인덱스 구축)\n",
    "# 한국어 입력 텍스트 데이터를 시퀀스로 변환\n",
    "# 한국어 타겟 텍스트 데이터를 시퀀스로 변환\n",
    "# 1500번째 한국어 입력 시퀀스 출력\n",
    "# 1500번째 한국어 타겟 시퀀스 출력\n",
    "# 1500번째 한국어 입력 시퀀스의 각 인덱스를 단어로 변환하여 리스트로 출력\n",
    "# 1500번째 한국어 타겟 시퀀스의 각 인덱스를 단어로 변환하여 리스트로 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3875df12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한국어 단어를 인덱스로 매핑한 사전 가져오기\n",
    "# 고유한 출력 토큰 수 출력\n",
    "# 사용할 단어 수 계산 (실제 단어 수 + 1)\n",
    "# 타겟 텍스트의 최대 길이 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a2207d",
   "metadata": {
    "id": "XujZjSHZG8zh"
   },
   "source": [
    "## sequence padding\n",
    "\n",
    "\n",
    "### 주의 사항\n",
    "- encoder 는 thought vector 생성 목적이므로 `pre`(default) 로 padding\n",
    "\n",
    "\n",
    "- decoder 는 teacher forcing 을 해야하므로 `post` 로 padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080c24e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 영어 시퀀스를 패딩 처리하여 인코더 입력으로 변환 (최대 길이 max_len_eng로 설정)\n",
    "# 한국어 입력 시퀀스를 패딩 처리하여 디코더 입력으로 변환 (최대 길이 max_len_kor로 설정, 'post' 방식으로 패딩)\n",
    "# 한국어 타겟 시퀀스를 패딩 처리하여 디코더 타겟으로 변환 (최대 길이 max_len_kor로 설정, 'post' 방식으로 패딩)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf1e724",
   "metadata": {
    "id": "TWIdoqQGG8zk"
   },
   "source": [
    "## pretrained word embedding 값을 transfer learning\n",
    "\n",
    "- Embedding layer 의 weight 를 pre-trained model 로 초기화  \n",
    "\n",
    "\n",
    "- glove.6B 의 EMBEDDING_DIM version 사용  \n",
    "    - space 로 구분된 text file\n",
    "    - 첫번째는 word 이고 두번째 이후는 weight vector 값이다\n",
    "\n",
    "\n",
    "- word index 가 1 부터 시작하므로 0 padding 감안하여 num_words 는 len(word2idx)+1, 혹은 MAX_VOCAB_SIZE 중 작은 것 선택  \n",
    "\n",
    "\n",
    "- embedding_dict dictionary : key - word, value - embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2add4826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용할 단어 수 계산 (최대 어휘 크기와 실제 단어 수 + 1 중 작은 값)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b320fa",
   "metadata": {
    "id": "VjrgS3RWG8zy"
   },
   "source": [
    "### embedding layer 작성\n",
    "\n",
    "- encoder 와 decoder 의 Embedding layer 에 pre-trained embedding weight 를 초기값으로 load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986f61de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임베딩 레이어 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4160492a",
   "metadata": {
    "id": "0lTBcpJ7G8z2"
   },
   "source": [
    "## Build model\n",
    "\n",
    "- encoder 와 decoder 의 embedding, lstm 및 dense layer 를 training 할 목적의 model 작성  \n",
    "\n",
    "- encoder 는 decoder 에 states [h, c] 만 전달\n",
    "\n",
    "- prediction 을 위한 model 은 training model 에서 만들어진 layer 들의 weight 를 이용하여 별도 작성  \n",
    "\n",
    "<img src=\"https://i.imgur.com/OBmjQQt.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145264cd",
   "metadata": {
    "id": "uahjsXKTG8z2"
   },
   "source": [
    "## Encoder model 작성  \n",
    "\n",
    "- Training과 Inference State 에서 모두 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d250fd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 정의\n",
    "# 인코더 입력 정의 (최대 길이를 max_len_eng로 설정)\n",
    "# 사전 학습된 임베딩 레이어 사용\n",
    "# LSTM 레이어를 사용하여 인코더 출력과 상태(hidden state와 cell state) 계산\n",
    "# 인코더는 hidden state와 cell state만 디코더로 전달 (thought vector)\n",
    "# 인코더 모델 정의\n",
    "# 인코더 모델 요약 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c20adcb",
   "metadata": {
    "id": "r4tlTKf0G8z5"
   },
   "source": [
    "## Decoder model for Teacher Forcing\n",
    "\n",
    "- Training stage 에서 만 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c339a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 정의\n",
    "# 디코더 입력 정의 (최대 길이를 max_len_kor로 설정)\n",
    "# 디코더의 단어 임베딩은 사전 학습된 벡터를 사용하지 않음\n",
    "# 교사 강요(Teacher-forcing)를 위한 디코더 LSTM 정의\n",
    "# 초기 상태를 인코더의 [h, c] 상태로 설정\n",
    "# 최종 Dense 레이어 정의\n",
    "# Teacher-forcing 모델 생성\n",
    "# 모델 컴파일 및 훈련 설정\n",
    "# 모델 요약 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda4188a",
   "metadata": {
    "id": "73rTNuLZIaiy"
   },
   "source": [
    "- teacher-forcing model 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6da965",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce75248b",
   "metadata": {
    "id": "5wbWW3D9IgZi"
   },
   "source": [
    "- teacher-forcing model train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7204662",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8132a82",
   "metadata": {
    "id": "XyUjTEg1IkC5"
   },
   "source": [
    "- accuracy, loss 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ba3a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot some data\n",
    "# accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d3ad72",
   "metadata": {
    "id": "7hQEWBi6IpGl"
   },
   "source": [
    "- save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8d370e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9f3564e",
   "metadata": {
    "id": "QXpQ5xqKG80E"
   },
   "source": [
    "## Make Predictions - Inference phase\n",
    "\n",
    "- prediction 을 위한 별도의 decoder model 작성  \n",
    "\n",
    "- 별로 training 없이 앞에서 train 된 weights 를 모두 재사용 한다.\n",
    "\n",
    "- decoder 는 encoder 와 분리되어 구성\n",
    "\n",
    "<img src=\"https://i.imgur.com/kOdKwg0.png\" width=600 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e2dab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추론(Inference)용 디코더 정의\n",
    "# 디코더 LSTM의 hidden state 입력 정의 (512 차원)\n",
    "# 디코더 LSTM의 cell state 입력 정의 (512 차원)\n",
    "# 디코더 상태 입력 리스트 생성\n",
    "# 디코더의 단일 단어 입력 정의 (1차원)\n",
    "# 단일 단어 입력을 임베딩 벡터로 변환\n",
    "# 출력과 hidden states 저장\n",
    "# 새로운 디코더 상태 리스트 생성\n",
    "# 디코더 출력에 Dense 레이어 적용\n",
    "# 추론용 디코더 모델 생성\n",
    "# 추론용 디코더 모델 요약 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5c4035",
   "metadata": {
    "id": "HOl_sDoVI1N7"
   },
   "source": [
    "- inference 용 decoder model 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83960798",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e1421d5",
   "metadata": {
    "id": "RTLcPG9RI8dR"
   },
   "source": [
    "예측하는 동안 index를 단어를 되돌리기 위한 reverse word2idx dictionary 작성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7605376",
   "metadata": {
    "id": "fUZfCBF-JKPR"
   },
   "source": [
    "### Translation Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002260ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 인코더 모델을 이용하여 입력을 상태 벡터로 인코딩\n",
    "    # 길이 1의 빈 타겟 시퀀스 생성\n",
    "    # 타겟 시퀀스의 첫 번째 단어를 시작 토큰(<sos>)으로 설정\n",
    "    # 종료 토큰(<eos>)이 디코딩에서 생성되면 루프 종료\n",
    "    # 번역문 생성\n",
    "        # 디코더 모델을 이용하여 다음 단어 예측 및 상태 업데이트\n",
    "        # argmax로 가장 확률 높은 단어 선택 (탐욕적 선택)\n",
    "        # 생성된 단어를 디코더의 다음 입력으로 사용\n",
    "        # 상태 업데이트\n",
    "# 번역 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20567aa9",
   "metadata": {
    "id": "Qjr59AvAJTqF"
   },
   "source": [
    "### 임의의 영어 입력을 처리하는 영한 번역 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734df412",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Eng_Kor_translation(txt):\n",
    "    # 입력된 영어 텍스트를 시퀀스로 변환\n",
    "    # 시퀀스를 패딩 처리하여 인코더 입력으로 변환 (최대 길이를 max_len_eng로 설정)\n",
    "    # 인코더 입력을 디코더 시퀀스로 변환하여 번역 결과 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f97b4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb12658",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
